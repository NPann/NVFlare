Quickstart (Numpy)
===================

Before You Start
----------------

Before jumping into this QuickStart guide, make sure you have an environment with `NVFlare <https://pypi.org/project/nvflare/>`_ installed.  You can follow
:doc:`installation <../installation>` on the general concept of Python virtual environment (the recommended environment) and how to
install NVFlare.


Introduction
-------------

This tutorial is meant to solely demonstrate how the NVFlare system works, without introducing any actual deep learning concepts.
Through this exercise, you will learn how to use NVFlare with numpy to perform basic computations across two clients.
Due to the simplified weights, you will be able to clearly see and understand the results of the FL aggregation and the model persistor process.

The design of this exercise consists of one **server** and two **clients**, starting with weights ``[0, 1]``.
The following steps compose one cycle of weight updates, called a **round**:

 #. Clients are responsible for adding (with some slight errors) the two weights together to calculate a Fibonacci number for the model. 
 #. These updates are then sent to the server which will aggregate them (averaging out the errors) to produce a model with new weights. 
 #. Finally, the server sends this updated version of the model back to each client, so the clients can continue to calculate the next Fibonacci number in future rounds.

For this exercise, we will be working with the ``hello-numpy`` application in the examples folder.
Every custom FL application must contain three folders:

 #. **custom**: contains the custom components (``trainer.py``, ``model_persistor.py``)
 #. **config**: contains client and server configurations (``config_fed_client.json``, ``config_fed_server.json``)
 #. **resources**: contains the logger config (``log.config``)

Let's get started. First clone the repo, if you haven't already:

.. code-block:: shell

  $ git clone https://github.com/nvidia/nvflare.git

Remember to activate your NVFlare Python virtual environment from the installation guide. Ensure numpy is installed.

.. code-block:: shell

  (nvflare-env) $ python3 -m pip install numpy

Now that you have all your dependencies installed, let's implement the Federated Learning system.


NVFlare Client
--------------
 
In a file called ``trainer.py``, import nvflare and numpy.
Now we will implement the train function to enable the clients to perform
a simple addition of two numbers to represent one calculation in the Fibonacci Sequence.

.. literalinclude:: ../../hello_nvflare/examples/hello-numpy/custom/trainer.py
   :language: python
   :linenos:
   :caption: trainer.py


The server sends either the initial weights of [0, 1] or any stored weights to each of the clients
through the ``Shareable`` object passed into ``train()``. Each client adds the
two numbers together, and creates a new ``Shareable`` to include the sum of the two 
numbers as well as the second number of original shareable.  
This represents the calculation of one term in the Fibonacci Sequence:

``[a, b] => [b, a + b]``
wherein ``a`` and ``b`` are two consecutive Fibonacci numbers, with ``b > a``.

In a real federated learning training scenario, each client does its training independently on its own dataset. 
As such, the weights returned to the server will likely be different for each of the clients. 
Because this exercise is simply doing an addition operation rather than a training on a dataset, we
**hard-code** a slight variation in the clients' addition to demonstrate how the server aggregation works. 
We define that client-1 always **subtracts** one extra from every element, while client-2 always 
**adds** one extra to every element.

Fortunately, because this is a FL system with two clients, the server can ``aggregrate``
(in this case average) the clients' results to produce the correct Fibonacci number.

You can learn more about ``Shareable`` and ``FLContext`` in the :doc:`hello_pt` exercise or in the :ref:`documentation <programming_guide:Key Objects>`.


NVFlare Server & Application
------------------------------

Model Persistor
^^^^^^^^^^^^^^^^^

.. literalinclude:: ../../hello_nvflare/examples/hello-numpy/custom/model_persistor.py
   :language: python
   :linenos:
   :caption: model_persistor.py

The model persistor is used to load and save models on the server. Here, the model is a ``Model`` object containing two calculated Fibonacci numbers.

The expected format of the ``Model`` object is a dictionary with keys of type ``str`` and values of type ``numpy.array``. 
This can be easily changed as long as all of the FL components agree on the format.

In this exercise, we can simply serialize the model dictionary using pickle and save it to weights.pickle 
inside the ``server/run_1/mmar_server/models/`` directory (weights file name specified in ``config_fed_client.json``).
Depending on the frameworks and tools, the methods of saving the model may vary.

.. note::

  Note that in our hello-examples, we are demonstrating Federated Learning using the familiar deep learning model concept.

  However, Federated Learning is not restricted to just deep learning and may not always involve models. Thus, 
  we define a :ref:`Learnable <programming_guide:Learnable>` object (subclasses ``dict``) as the most general form of data object generated through Federated Learning.
  The ``Model`` class we are using here is simply a subclass of ``Learnable``.


Application Configuration
^^^^^^^^^^^^^^^^^^^^^^^^^^

Inside the config folder there are two files, ``config_fed_client.json`` and ``config_fed_server.json``.
For now, the default configurations are sufficient.


.. literalinclude:: ../../hello_nvflare/examples/hello-numpy/config/config_fed_server.json
   :language: json
   :linenos:
   :caption: config_fed_server.json


Note that the ``persistor`` points to the custom ``NumpyModelPersistor`` with full Python module path.


.. literalinclude:: ../../hello_nvflare/examples/hello-numpy/config/config_fed_client.json
   :language: json
   :linenos:
   :caption: config_fed_client.json


Here, the ``client_trainer`` points to the Trainer implementation ``SimpleTrainer``.


Federated Numpy Fibonacci!
--------------------------

Now you must set up a local environment and generate packages to simulate the server, clients, and admin.

Setting Up the Application Environment
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
This command generates a poc folder with server, one client and one admin:

.. code-block:: shell

    $ poc

Here we duplicate the client folder into two folders to create two clients, site-1 and site-2:

.. code-block:: shell

    $ cp -r poc/client poc/site-1
    $ cp -r poc/client poc/site-2

Finally, we copy necessary files (the exercise codes) to a working folder:

.. code-block:: shell

  $ mkdir -p poc/admin/transfer
  $ cp -rf examples/* poc/admin/transfer

With both the client and server ready, you can now run everything and see federated
learning in action. FL systems usually have a server and multiple clients. We
therefore have to start the server first:

.. code-block:: shell

    $ ./poc/server/startup/start.sh

Once the server is running you can start the clients in different terminals.
Open a new terminal and start the first client:

.. code-block:: shell

    $ ./poc/site-1/startup/start.sh site-1 localhost

Open another terminal and start the second client:

.. code-block:: shell

    $ ./poc/site-2/startup/start.sh site-2 localhost

In one last terminal, start the admin:

.. code-block:: shell

  $ ./poc/admin/startup/fl_admin.sh localhost


This will launch a command prompt, where you can input commands to control and monitor many aspects of
the FL process. Log in by entering ``admin`` for both the username and password.

Running the FL
^^^^^^^^^^^^^^

Enter the commands below in order.  Pay close attention to what happens in each of four terminals.  You
can see the admin controls server and clients with each command.

.. code-block:: shell

    > upload_app hello-numpy

Uploads an application in the server's registry.  This creates the application entry, populates the configuration and links the name
``hello-numpy`` with such application configuration.  Later, you can control this application via this name.

.. code-block:: shell

    > set_run_number 1

Creates a workspace with the run_number on the server and all clients.  The purpose of this workspace is to isolate different runs so
the information in one particular run does not interfere with other runs.

.. code-block:: shell

    > deploy_app hello-numpy all

This will make the hello-numpy application the active one in the run_number workspace.  After the above two commands, the
server and all the clients know the hello-numpy application will reside in the ``run_1`` workspace.


.. code-block:: shell

    > start_app all

This ``start_app`` command instructs the NVFlare server and clients to start training with the hello-numpy application in that ``run_1`` workspace.

From time to time, you can issue ``check_status server`` in the admin client to check the entire training progress.

You should now see how the training does in the very first terminal (the one that started the server):


Understanding the Output
^^^^^^^^^^^^^^^^^^^^^^^^^

After starting the server and clients, you should begin to see 
some outputs in each terminal tracking the progress of the fl run. If everything went as 
planned, you should see that through 10 rounds, the FL system has calculated the correct 
numbers in the Fibonacci Sequence: ``0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89``

Here are some snippets of the output that you can follow along with. 

.. code-block:: shell
    :caption: site-1

    Get global model for round: 6
    pull_models completed. Status:True rank:0
    site-1 Shareable from server:  {'sequence': array([ 8., 13.])}
    site-1 Updated Shareable to server:  {'sequence': array([12., 20.])}

    Send model to server.
    2021-07-01 16:22:28,431 - FederatedClient - INFO - Starting to push model.
    2021-07-01 16:22:28,432 - Communicator - INFO - Send example_project at round 6

.. code-block:: shell
    :caption: site-2

    Get global model for round: 6
    pull_models completed. Status:True rank:0
    site-2 Shareable from server:  {'sequence': array([ 8., 13.])}
    site-2 Updated Shareable to server:  {'sequence': array([14., 22.])}

    Send model to server.
    2021-07-01 16:22:31,462 - FederatedClient - INFO - Starting to push model.
    2021-07-01 16:22:31,463 - Communicator - INFO - Send example_project at round 6

.. code-block:: shell
    :caption: server

    2021-07-01 16:22:38,453 - FederatedServer - INFO - > aggregating: 6
    2021-07-01 16:22:38,453 - AccumulateWeightedAggregator - INFO - aggregating 2 updates at round 6
    Saving aggregated server weights:  {'sequence': array([13., 21.])}

As you can see, on round 6 both of the clients receive ``[8, 13]`` from the server. However, instead of sending back ``[13, 8 + 13] = [13, 21]``, due to the built in biases, site-1 sends back ``[12, 20]`` and site-2 sends back ``[14, 22]`` to the server.

Finally, through aggregating the clients' results, the server saves the weights for round 6 with the correct sequence of ``[13, 21]``.

Once the fl run is complete and the server has successfully aggregrated the client's results after all the rounds, run the following commands in the fl_admin to shutdown the system (while inputting ``admin`` when prompted with password):

.. code-block:: shell

    > shutdown client
    > shutdown server
    > bye

In order to stop all processes, run ``./stop_fl.sh``. 

If you want to reset the saved server weights to start from ``[0,1]`` again, delete ``weights.pickle`` in the ``server/run_1/mmar_server/models/`` directory.

Congratulations!
You've successfully built and run your first numpy federated learning system. 
You now have a decent grasp of the main FL concepts, and are ready to start exploring how NVFlare can be applied to many other tasks.
